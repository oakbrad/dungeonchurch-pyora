name: Sync Static Assets to OCI Object Storage

# This workflow syncs the contents of the 'static' folder to an OCI Object Storage bucket
# using rclone with OCI's S3-compatible API.
#
# REQUIRED SECRETS (using OCI Customer Secret Keys, not API keys):
# - OCI_S3_ACCESS_KEY: Access Key from Customer Secret Keys
# - OCI_S3_SECRET_KEY: Secret Key from Customer Secret Keys
# - OCI_NAMESPACE: Your tenancy's Object Storage namespace
# - OCI_CLI_REGION: OCI region (e.g., us-ashburn-1)
# - WORKFLOW_DISPATCH_TOKEN: PAT with write:repository scope (for triggering URL update workflow)
#
# To generate Customer Secret Keys:
# 1. OCI Console → Profile → User Settings
# 2. Scroll to "Customer Secret Keys" → "Generate Secret Key"
# 3. Save both the Access Key and Secret Key (secret only shown once)
#
# To find your namespace:
# 1. OCI Console → Object Storage → Buckets
# 2. The namespace is shown in the bucket details

on:
  push:
    branches:
      - main
    paths:
      - 'static/**'

  workflow_dispatch:

jobs:
  sync-assets:
    name: Sync static assets to OCI bucket
    runs-on: docker
    container:
      image: rclone/rclone:latest
    outputs:
      files_synced: ${{ steps.sync.outputs.files_synced }}

    steps:
      - name: Checkout repository
        run: |
          apk add --no-cache git
          git clone --depth 1 $GITHUB_SERVER_URL/$GITHUB_REPOSITORY.git .

      - name: Sync to OCI Object Storage
        id: sync
        env:
          RCLONE_CONFIG_OCI_TYPE: s3
          RCLONE_CONFIG_OCI_PROVIDER: Other
          RCLONE_CONFIG_OCI_ACCESS_KEY_ID: ${{ secrets.OCI_S3_ACCESS_KEY }}
          RCLONE_CONFIG_OCI_SECRET_ACCESS_KEY: ${{ secrets.OCI_S3_SECRET_KEY }}
          RCLONE_CONFIG_OCI_ENDPOINT: https://${{ secrets.OCI_NAMESPACE }}.compat.objectstorage.${{ secrets.OCI_CLI_REGION }}.oraclecloud.com
          RCLONE_CONFIG_OCI_REGION: ${{ secrets.OCI_CLI_REGION }}
        run: |
          set -eo pipefail
          rclone sync static/ oci:dungeonchurch-content/5e/ \
            --checksum \
            --verbose \
            2>&1 | tee /tmp/rclone.log

          # Fail if any errors occurred
          if grep -q "^.*ERROR" /tmp/rclone.log; then
            echo "Errors detected during sync"
            exit 1
          fi

          # Check if any files were actually transferred
          if grep -q "Copied (new)\|Copied (replaced)\|Deleted" /tmp/rclone.log; then
            echo "files_synced=true" >> $GITHUB_OUTPUT
            echo "Files were synced to bucket"
          else
            echo "files_synced=false" >> $GITHUB_OUTPUT
            echo "No files needed syncing"
          fi

  trigger-url-update:
    name: Trigger URL replacement workflow
    needs: sync-assets
    if: needs.sync-assets.outputs.files_synced == 'true'
    runs-on: docker
    container:
      image: alpine:latest
    steps:
      - name: Trigger URL update workflow
        env:
          TOKEN: ${{ secrets.WORKFLOW_DISPATCH_TOKEN }}
        run: |
          apk add --no-cache curl

          # Trigger workflow dispatch via Forgejo API
          # Uses current branch so it works from feature branches and main
          curl -X POST \
            -H "Authorization: token ${TOKEN}" \
            -H "Content-Type: application/json" \
            -d "{\"ref\": \"${GITHUB_REF_NAME}\"}" \
            "${GITHUB_SERVER_URL}/api/v1/repos/${GITHUB_REPOSITORY}/actions/workflows/update-asset-urls.yaml/dispatches" \
            -v
